[
  {
    "title": "和众汇富研究手记:英伟达推动H200争取重返中国市场",
    "content": "外媒 11 月 21 日报道称,特朗普政府正在考虑允许英伟达向中国销售 H200 人工智能芯片,这一型号此前与 A100 H100 等高端 GPU 一样被列入出口管制名单 围绕高端 AI 芯片出口的政策微调...",
    "url": "http://app.myzaker.com/article/692522361bc8e06532000005",
    "source": "Unkown",
    "scraped_at": "2025-11-26T09:55:07.991817",
    "published_date": "2025-11-25"
  },
  {
    "title": "H200芯片若重返中国市场影响几何 国产GPU面临新挑战",
    "content": "短期来看, 买美货 仍是主选项 2024年,在H100 H800被严控后,中国企业大量采购为中国市场特供的H20,据RAND引用数据估算,中国公司在2024年约买了100万颗H20,而同期华为昇腾910B的出货量约为45万颗 这说明在性能和生态考虑下,只要能买到且合规,英伟达仍然是中国企业的...",
    "url": "https://news.china.com/socialgd/10000169/20251124/49017572.html",
    "source": "Unkown",
    "scraped_at": "2025-11-26T09:55:07.993324",
    "published_date": "2025-11-24"
  },
  {
    "title": "美国或批准英伟达向中国出售H200人工智能芯片",
    "content": "然而,近期美中关系的缓和为这一政策带来了转机 H200芯片作为英伟达首款搭载HBM3e存储器的GPU,与前一代A100相比,存储器容量提升近一倍,带宽提高约2.4倍,最高可达141GB容量与每秒4.8TB的传输速度,使其在执行推论任务时具备更强效能 还处于内部讨论中 据知情人士透露,...",
    "url": "https://www.eet-china.com/news/202511246457.html",
    "source": "Unkown",
    "scraped_at": "2025-11-26T09:55:07.993782",
    "published_date": "2025-11-24"
  },
  {
    "title": "H200芯片若重返中国市场影响几何 国产GPU面临新挑战(2)",
    "content": "大模型创业公司会重新评估拿什么芯片堆第一名,很多公司会有自然冲动将旗舰模型先堆在H200上跑,国产芯片用来做推理和产品化落地 这会带来明显变化:国产GPU从被迫从零到一进入与英伟达同场竞技的阶段 从国产厂商的视角看,H200放行带来的短期压力非常现实 一部分原本...",
    "url": "https://news.china.com/socialgd/10000169/20251124/49017572_1.html",
    "source": "Unkown",
    "scraped_at": "2025-11-26T09:55:07.994236",
    "published_date": "2025-11-24"
  },
  {
    "title": "阿里云推出全新AI计算解决方案:大模型所需GPU狂降82 !",
    "content": "通过组件复用 显存精细化管理和KV缓存同步优化等全栈技术 Aegaeon将模型切换开销降低了97 确保了token级调度的实时性 可支持亚秒级的模型切换响应 在阿里云模型市场为期超三个月的Beta测试中 Aegaeon系统在服务数十个参数量高达720亿的大模型时 所需的NVIDIA...",
    "url": "https://baijiahao.baidu.com/s?id=1846557516077952260&wfr=spider&for=pc",
    "source": "Unkown",
    "scraped_at": "2025-11-26T09:55:07.996497",
    "published_date": "2010-11-21"
  },
  {
    "title": "阿里云GPU池化系统可减少82 NvidiaH20,用于多大型语言模型",
    "content": "经过阿里云模型市场为期三个月的Beta测试,Aegaeon系统展现出卓越的性能优化能力 在服务参数量高达720亿的数十个大型语言模型的实际场景中,系统将所需的NvidiaH20GPU数量从1192张成功...",
    "url": "https://www.huxiu.com/ainews/4628.html",
    "source": "Unkown",
    "scraped_at": "2025-11-26T09:55:07.996914",
    "published_date": "2010-11-20"
  }
]